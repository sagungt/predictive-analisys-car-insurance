# -*- coding: utf-8 -*-
"""Predictive Analisys - Car Insurance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ganQrX9yONEjVna_FiBsVUDq7NH1y4EW

# Introduction

by: Sri Agung Tirtayasa

dataset: https://www.kaggle.com/datasets/sagnik1511/car-insurance-data

# Preparation
"""

# Commented out IPython magic to ensure Python compatibility.
# Import all required library

# Computing, Plot, Data processing
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
# %matplotlib inline

# Utilities
from google.colab import files
import time

# Data preprocessing
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import RFECV

# Algorithms for model
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Metrics
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score

# Hyperparameter tuning
from sklearn.model_selection import GridSearchCV

# Upload kaggle credentials

files.upload()

# Make directory for credentials and dataset

!mkdir -p ~/.kaggle
!mkdir -p dataset
!mv ./kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!pip install -q kaggle

# Download dataset https://www.kaggle.com/datasets/sagnik1511/car-insurance-data

!kaggle datasets download -d sagnik1511/car-insurance-data

!unzip car-insurance-data.zip -d ./dataset

dataset = pd.read_csv('./dataset/Car_Insurance_Claim.csv')
dataset.tail(10)

"""# Data Understanding

Features:

1. ID: ID dari setiap data
2. AGE: Umur pelanggan, dibedakan menjadi beberapa kategori dari rentang umur:

  - 16-25 Tahun
  - 26-39 Tahun
  - 40-64 Tahun
  - 65+ Tahun

3. GENDER: Jenis kelamin pelanggan
4. RACE: Ras pelanggan dibagi menjadi 2 Mayoritas dan Minoritas
5. DRIVING_EXPERIENCE: Pengalaman berkendara dari pelanggan, dibagi menjadi beberapa kategori dari tahun pengalaman:

  - 0-9 Tahun
  - 10-19 Tahun
  - 20-29 Tahun
  - 30+ Tahun

6. EDUCATION: Pendidikan terakhir pelanggan, dibagi menjadi 3 kategori:

  - None: tidak ada atau tidak terdata
  - Highschool (SMA)
  - University (Kuliah)

7. INCOME: Pendapatan pelanggan, dibagi menjadi 4 kategori:

  - Proverty (Rakyat kelas bawah/miskin)
  - Middle Class (Rakyat kelas menengah kebawah)
  - Working Class (Rakyat kelas menengah keatas)
  - Upper Class (Rakyat kelas atas/kaya)

8. CREDIT_SCORE: Seberapa besar kemungkinan Anda mengajukan klaim
9. VEHICLE_OWNERSHIP: Kepemilikan kendaraan
10. VEHICLE_YEAR: Tahun keluaran mobil, dibedakan manjadi sebelum 2015 dan setelah 2015
11. MARRIED: Status nikah pelanggan
12. CHILDREN: Jumlah anak pelanggan
13. POSTAL_CODE: Kode pos pelanggan
14. ANNUAL_MILEAGE: Jarak tempuh mobil tahunan
15. VEHICLE_TYPE: Tipe mobil dibagi menjadi sedan dan mobil sport
16. SPEEDING_VIOLATIONS: Jumlah riwayat pelanggaran melewati batas kecepatan jalanan
17. DUIS: (*Driving Under Influence*) Jumlah riwayat pelanggan mengandarai sambil mabok dsb.
18. PAST_ACCIDENTS: Jumlah riwayat kecelakaan pelanggan
19. OUTCOME: Penerima asuransi
"""

dataset.info()e

"""# EDA"""

dataset.describe()

dataset.drop(['ID'], axis=1, inplace=True)
dataset.shape

dataset.columns

dataset.isnull().any()

"""Terdapat data kosong pada dataset sebesar 1851 baris

Ada beberapa cara untuk mengatasi baris yang kosong seperti mengisi dengan nilai MEAN, MEDIAN dll.

Tapi sekarang kita gunakan teknik termudah yaitu cukup dengan menghapus semua baris data yang kosong
"""

nan_rows = dataset[dataset['CREDIT_SCORE'].isnull() | dataset['ANNUAL_MILEAGE'].isnull()]
nan_rows

# Drop NA values

dataset = dataset.dropna(how="any", axis=0)
dataset.isnull().any()

dataset.shape

dataset.info()

dataset.nunique()

dataset.select_dtypes('int').describe()

dataset.head()

"""Mayoritas data merupakan data kategorikal

Kita pisahkah kategorikan dengan numerikal berdasarkan jumlah unique valuenya

Numerical features = unique values >= 15
"""

numerical = ['SPEEDING_VIOLATIONS', 'ANNUAL_MILEAGE', 'PAST_ACCIDENTS', 'CREDIT_SCORE']
categorical = ['AGE', 'GENDER', 'DRIVING_EXPERIENCE', 'EDUCATION', 'INCOME', 'VEHICLE_OWNERSHIP', 'VEHICLE_YEAR', 'MARRIED', 'CHILDREN', 'POSTAL_CODE', 'VEHICLE_TYPE', 'DUIS', 'RACE']

"""Sebaran data pada fitur target ternyata tidak seimbang walaupun tidak terlalu besar (*imbalance*)

31.1 % dapat asuransi

68.9 % tidak dapat asuransi

Pada saat data preprocessing nanti akan kita handle menggunakan teknik *Oversampling*
"""

# Plot target ratio to pie chart
# 1: Accepted
# 0: Rejected

outcome = dataset['OUTCOME'].value_counts()
outcome.plot.pie(autopct='%1.1f%%')
accept, reject = outcome
print(f"Accepted insurance {accept}")
print(f"Rejected insurance {reject}")

dataset.loc[:, numerical]

y = dataset['OUTCOME']
X = dataset.drop('OUTCOME', axis=1)

data = X[numerical]
data = (data-data.mean()) / (data.std())
data = pd.melt(
    pd.concat([data, y], axis=1),
    id_vars="OUTCOME",
    var_name="Features",
    value_name="Value",
)

f, ax = plt.subplots(1, 2, figsize=(20, 10))

sns.violinplot(x="Features", y="Value", hue="OUTCOME", data=data, split=True, inner="quart", ax=ax[0], scale='count', scale_hue=True)
sns.boxplot(x="Features", y="Value", data=data, ax=ax[1])
plt.xticks(rotation=90)

"""- Dari visualisasi violinplot diatas perbedaan atara penerima asuransi dan yang bukan penerima tidak terklasifikasikan dengan baik
- Pada visualisasi boxplot terlihat ada outliers pada dataset, kita tidak akan menghilangkan outliers karena dapat menghilangkan data di beberapa fitur

"""

f, ax = plt.subplots(3, 5, figsize=(20, 20))

for i, feature in enumerate(categorical):
  pd.crosstab(X[feature], y).plot(kind='bar', title=feature, ax=ax[i // 5][i % 5])

"""- Pada fitur AGE terlihat pada kategori umur rentang 15-24 peluang untuk mendapatkan asuransi mobil cukup tinggi, dan semakin besar umur semakin kecil
- Pada fitur DRIVING_EXPERIENCE terlihat pada kategori 0-9 tahun pengalaman berkendara berpeluang mendapatkan asuransi, semakin berpengalaman semakin kecil peluang mendapatkan asuransi
- Begitu juga pada fitur INCOME, untuk kategori '*proverty*' terlihat berbedaan peluang pendapatan asuransi
- Peluang mendapatkan asuransi lebih besar pada GENDER laki-laki daripada perempuan
"""

dataset.hist(bins=50, figsize=(20,15))
plt.show()

for col in categorical:
  sns.catplot(x=col, y='OUTCOME', kind='bar', dodge=False, height=4, aspect=3, data=dataset, palette='Set1')
  plt.title("Averaga 'OUTCOME' relative to - {}".format(col))

sns.pairplot(dataset, diag_kind='hist', hue='OUTCOME')

le = LabelEncoder()

for col in numerical:
  X[col] = le.fit_transform(X[col])

for col in categorical:
  X = pd.concat([X, pd.get_dummies(X[col], prefix=col)], axis=1)

X.drop(categorical, axis=1, inplace=True)
X

plt.figure(figsize=(20, 16))
correlation_matrix = pd.concat([X, y], axis=1).corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidth=0.5)
plt.title('Correlation Matrix', size=20)

"""Hasil dari correlation matrix terdapat fitur beberapa fitur yang paling kurang berkorelasi dengan OUTCOME yaitu:

- VEHICLE_TYPE_sedan
- VEHICLE_TYPE_sports car
- DUIS_2
- DUIS_3
- DUIS_4
- DUIS_5
- DUIS_6

Pada saat ini kita tidak akan menghapus fitur tersebut, tetapi pada tahap Hyperparameter Tuning kita akan analisa fitur yang paling berpengaruh pada model menggunakan RFECV (*Recursive Feature Elimination with Cross Validation*)

# Data Preparation
"""

X_copy = X.copy()
X_copy.tail()

X_copy.info()

X_train, X_test, y_train, y_test = train_test_split(X_copy, y, test_size=0.3, random_state=123)

"""Handle imbalance dataset with oversampling

> **SMOTE (*Synthetic Minority Oversampling Technique*)**
> Teknik SMOTE ini tidak hanya membuat duplikasi dari kelas minoritas, tetapi mengambil fitur target dan juga fitur yang lain (*neighbors*) lalu menghasilkan data baru dari kombinasi tersebut

> https://imbalanced-learn.org/stable/over_sampling.html#smote-variants
> https://www.fromthegenesis.com/smote-synthetic-minority-oversampling-technique/

"""

oversample = SMOTE(random_state=33)
X_train, y_train = oversample.fit_resample(X_train, y_train)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

X_copy.describe().transpose()

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Model

Kita akan menggunakan beberapa algoritma klasifikasi yaitu

- Logistic Regression
- Random Forest
- XGBoost
- Support Vector Classifier (SVC)

Setelah evaluasi base model, kita coba tuning hyperparameter dengan GridSearchCV untuk mencari parameter yang cocok untuk model

Selain itu dikarenakan kita tidak menghapus fitur yang berkorelasi rendah, kita coba validasi dengan RFECV (*Recursive Feature Elimination with Cross Validation*) untuk mencari fitur yang memiliki pengaruh tinggi terhadap model
"""

LR = LogisticRegression(random_state=200)
LR.fit(X_train, y_train)

XGB = XGBClassifier()
XGB.fit(X_train, y_train)

RF = RandomForestClassifier(n_estimators=50, max_depth=15, random_state=123, n_jobs=-1)
RF.fit(X_train, y_train)

SV = SVC(gamma='auto')
SV.fit(X_train, y_train)

accuracy_models = pd.DataFrame(index=['train_accuracy', 'test_accuracy'], columns=['Logistic', 'XGB', 'RandomForest', 'SVC'])
columns = {'Logistic': LR, 'XGB': XGB, 'RandomForest': RF, 'SVC': SV}

for col, model in columns.items():
  train_pred = model.predict(X_train)
  train_accuracy = accuracy_score(train_pred, y_train)
  accuracy_models.loc['train_accuracy', col] = train_accuracy

  test_pred = model.predict(X_test)
  test_accuracy = accuracy_score(test_pred, y_test)
  accuracy_models.loc['test_accuracy', col] = test_accuracy

accuracy_models

fig, ax = plt.subplots()
accuracy_models.plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Performa model lumayan bagus untuk algoritma Logistic Regression dan Support Vector Classifier dengan accuracy 84%

# Hyperparameter Tuning

> GridSearchCV merupakan teknik untuk mencari parameter terbaik untuk model. Teknik ini menggunakan Cross Validation untuk mengevaluasi performa dari setiap kombinasi dari parameter. Semakin banyak hyperparameter yang diinputkan semakin lama evaluasi dari grid search

> https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html

Hyperparameter yang akan di-*tuning*:

- max_depth: Kedalaman maksimum dari pohon (*node/tree*)
- n_esimators: Jumlah pohon (*nodes/trees*)
- criterion: Fungsi untuk mengukur kualitas dari percabangan
"""

parameters = {
    'max_depth': [10, 12, 13],
    'n_estimators': [100, 150, 200],
    'criterion': ['gini','entropy'],
    'random_state': [0]
  }

rf_clf = GridSearchCV(
    RandomForestClassifier(),
    parameters,
    cv=3,
    scoring='accuracy',
    verbose=2,
)

rf_clf.fit(X_train, y_train)
rf_clf.best_params_, rf_clf.best_score_

RF_G = RandomForestClassifier(**rf_clf.best_params_)
RF_G.fit(X_train, y_train)

train_pred = RF_G.predict(X_train)
train_accuracy = accuracy_score(train_pred, y_train)

test_pred = RF_G.predict(X_test)
test_accuracy = accuracy_score(test_pred, y_test)

train_accuracy, test_accuracy

"""Hyperparameter yang akan di-*tuning*:

- max_depth: Kedalaman maksimum dari pohon (*node/tree*)
- learning_rate: Jumlah pengurangan untuk mencegah overfitting
- eval_metric: Evaluasi metric (menggunakan 'error' saja karena untuk binary classification)
"""

parameters = {
    "max_depth": [ 3, 4, 5, 6, 8],
    'learning_rate': [0.01, 0.05, 0.1],
    'eval_metric': ['error'],
}

xgb_clf = GridSearchCV(
    XGBClassifier(),
    parameters,
    cv=5,
    scoring='accuracy',
    verbose=2,
)

xgb_clf.fit(X_train, y_train)
xgb_clf.best_params_, xgb_clf.best_score_

XGB_G = XGBClassifier(**xgb_clf.best_params_)
XGB_G.fit(X_train, y_train)

train_pred = XGB_G.predict(X_train)
train_accuracy = accuracy_score(train_pred, y_train)

test_pred = XGB_G.predict(X_test)
test_accuracy = accuracy_score(test_pred, y_test)

train_accuracy, test_accuracy

"""Hyperparameter yang akan di-*tuning*:

- C: Parameter regularisasi
- gamma: Koefisien kernel untuk 'rbf', 'poly' dan 'sigmoid'
- kernel: Fungsi untuk mengukur kualitas dari percabangan
"""

parameters = {
    'C': [0.25, 0.5, 0.75, 1],
    'gamma': ['auto'],
    'kernel': ['linear','rbf']
}

svc_clf = GridSearchCV(
    SVC(),
    parameters,
    cv=5,
    scoring='accuracy',
    verbose=2,
)

svc_clf.fit(X_train, y_train)
svc_clf.best_params_, svc_clf.best_score_

SV_G = SVC(**svc_clf.best_params_)
SV_G.fit(X_train, y_train)

train_pred = SV_G.predict(X_train)
train_accuracy = accuracy_score(train_pred, y_train)

test_pred = SV_G.predict(X_test)
test_accuracy = accuracy_score(test_pred, y_test)

train_accuracy, test_accuracy

"""Hyperparameter yang akan di-*tuning*:

- C: Inverse dari regularisasi
- max_iter: Jumlah iterasi maksimal
"""

parameters = {
    'C': [0.25, 0.5, 0.75, 1],
    'random_state': [0],
    'max_iter': [200, 250, 300],
  }

lr_clf = GridSearchCV(
    LogisticRegression(),
    parameters,
    cv=5,
    scoring='accuracy',
    verbose=2,
)

lr_clf.fit(X_train, y_train)
lr_clf.best_params_, lr_clf.best_score_

LR_G = LogisticRegression(**lr_clf.best_params_)
LR_G.fit(X_train, y_train)

train_pred = LR_G.predict(X_train)
train_accuracy = accuracy_score(train_pred, y_train)

test_pred = LR_G.predict(X_test)
test_accuracy = accuracy_score(test_pred, y_test)

train_accuracy, test_accuracy

"""**RFECV (*Recursive Feature Elimination with Cross Validation*)**

RFECV merupakan metode feature elimination yang bekerja secara rekursif mengeliminasi fitur dengan menggunakan Cross Validation juga untuk mencari fitur yang paling optimal

https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV
"""

clf_rf_rfecv = RandomForestClassifier()
rfecv = RFECV(estimator=clf_rf_rfecv, step=1, cv=5, scoring='accuracy', verbose=2)
rfecv = rfecv.fit(X_train, y_train)

print('Optimal number of features :', rfecv.n_features_)
print('Best features :', X_copy.columns[rfecv.support_])

"""Hasil dari RFECV mendapatkan jumlah fitur yang paling optimal yaitu 37 fitur

Sesuai dengan hasil dari correlation matrix, ada 7 fitur yang paling kurang berkorelasi

# Evaluation

Metrics yang digunakan

- Accuracy: Persentase dari semua prediksi yang diklasifikasikan dengan benar
\begin{array}{rcl}
accuracy & = & \dfrac{TP + TN}{TP + FP + TN + FN}
\end{array}
- Precission: Prediksi positif yang benar relatif terhadap total prediksi positif
\begin{array}{rcl}
precission & = & \dfrac{TP}{TP + FP}
\end{array}
- Recall: Prediksi positif yang benar relatif terhadap positif total
\begin{array}{rcl}
recall & = & \dfrac{TP}{TP + FN}
\end{array}
- F1 Score: Harmony mean dari *pricission* dan *recall*
\begin{array}{rcl}
F1 & = & \dfrac{2 * precission * recall}{precission + recall}
\end{array}
- ROC AUC: Kurva ROC (*Receiver Operating Characteristic*) untuk mengevaluasi ambang batas yang berbeda untuk masalah pembelajaran mesin klasifikasi. AUC (Area Under the Curve) mereprentasikan seluruh area dua dimensi di bawah kurva ROC

- Confusion Matrix: Menentukan tingkat kesalahan dalam prediksi klasifikasi.

Note:
- TP: *True Positive* adalah nilai positif yang diprediksi dengan benar
- TN: *True Negative* adalah nilai negatif yang diprediksi dengan benar
- FP: *False Positive* adalah nilai positif yang diprediksi dengan salah
- FN: *False Negative* adalah nilai negatif yang diprediksi dengan salah
"""

accuracies = pd.DataFrame(index=['accuracy'], columns=['LogisticRegression', 'RandomForest', 'XGBClassifier', 'SVC'])

def describe_model(model, model_key):
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  y_prob = model.predict_proba(X_test)[:, 1]
  cm = confusion_matrix(y_test, y_pred)

  print(classification_report(y_test, y_pred))
  print(f"Accuracy : {accuracy_score(y_test, y_pred)}")
  print(f"ROC AUC : {roc_auc_score(y_test, y_prob)}")

  plt.figure(figsize=(5,5))
  sns.heatmap(cm, annot=True, fmt="d")
  plt.title('Confusion matrix')
  plt.ylabel('Actual label')
  plt.xlabel('Predicted label')

  accuracy = accuracy_score(y_test, y_pred) * 100
  accuracies.loc['accuracy', model_key] = accuracy

  false_pos_rate, true_pos_rate, tresholds = roc_curve(y_test, y_prob)
  roc_auc = auc(false_pos_rate, true_pos_rate)

  plt.figure(figsize=(5, 5))
  plt.plot(false_pos_rate, true_pos_rate, label="AUC = %0.3f" % roc_auc, color='red')
  plt.legend(loc="lower right")
  plt.axis('tight')
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('ROC AUC Curve')
  plt.legend()
  plt.show()

model = LogisticRegression(**lr_clf.best_params_)
describe_model(model, 'LogisticRegression')

"""Hasil dari model logistic regression sesudah tuning hyperparameter tidak menunjukan peningkatan pada akurasi model

Confusion matrix menunkukan kesalahan 189 dan 182 pada prediksi

Skor AUC menunjukan hasil yang bagus dengan skor 0.918
"""

model = RandomForestClassifier(**rf_clf.best_params_)
describe_model(model, 'RandomForest')

"""Hasil dari model random forest sesudah tuning hyperparameter menunjukan sedikit peningkatan pada akurasi model

Confusion matrix menunkukan kesalahan 169 dan 219 pada prediksi

Skor AUC menunjukan hasil yang bagus dengan skor 0.908
"""

model = XGBClassifier(**xgb_clf.best_params_)
describe_model(model, "XGBClassifier")

"""Hasil dari model XGBoost sesudah tuning hyperparameter menunjukan sedikit peningkatan pada akurasi model

Confusion matrix menunkukan kesalahan 172 dan 209 pada prediksi

Skor AUC menunjukan hasil yang bagus dengan skor 0.915
"""

model = SVC(**svc_clf.best_params_, probability=True)
describe_model(model, 'SVC')

"""Hasil dari model SVC sesudah tuning hyperparameter tidak menunjukan peningkatan pada akurasi model

Confusion matrix menunkukan kesalahan 187 dan 184 pada prediksi

Skor AUC menunjukan hasil yang bagus dengan skor 0.918
"""

accuracies.plot(kind='barh')

accuracies

"""# Summary

- Model **Logistic Regression** dan **SVC** mendapatkan nilai yang hampir sama dengan akurasi 84.8%, untuk skor AUC Logistic regression lebih tinggi dengan skor 0.918
- Setelah menggunakan Grid Search untuk hyperparameter tuning hanya 2 model saja yang mendapat peningkatan akurasi, itupun hanya sedikit
- Untuk meningkatkan accuracy model mungkin bisa dilakukan feature selection ataupun feature extraction pada beberapa fitur
- Untuk mengatasi imbalance data dapat juga dilakukan dengan Class Weighting
"""